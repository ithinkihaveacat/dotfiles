#!/usr/bin/env bash

# context - Generate aggregated context for various topics
#
# Each topic is a bash function that uses fetch() to download GitHub repos
# and run() to output content in a shell_session XML format.

# Bash 4.0 or higher required for robust string manipulation
if ((BASH_VERSINFO[0] < 4)); then
  echo "$(basename "$0"): requires bash 4.0 or higher (found ${BASH_VERSION})" >&2
  exit 1
fi

set -eo pipefail

SCRIPT_NAME=$(basename "$0")

# Dynamic Topics Directory
CONTEXT_BASE_DIR="${XDG_DATA_HOME:-$HOME/.local/share}/context"

# =============================================================================
# HELPER FUNCTIONS
# =============================================================================

require() {
  hash "$@" || {
    echo "$SCRIPT_NAME: command '$1' not found" >&2
    exit 127
  }
}

xml_escape() {
  sed 's/&/\&amp;/g; s/</\&lt;/g; s/>/\&gt;/g'
}

cdata_escape() {
  tr -d '\000-\010\013\014\016-\037' | sed 's/]]>/]]]]><![CDATA[>/g'
}

# run DISPLAY_CMD COMMAND [ARGS...]
#
# Captures a command and its output as XML. The first argument is displayed
# in the <command> element. The remaining arguments are the command to execute.
# Exits on failure.
run() {
  local display_cmd="$1"
  shift
  local output

  if ! output=$("$@"); then
    echo "$SCRIPT_NAME: command failed: $display_cmd" >&2
    exit 1
  fi

  printf "<entry>\n"
  printf "<command>%s</command>\n" "$(printf '%s' "$display_cmd" | xml_escape)"
  printf "<output><![CDATA[%s]]></output>\n" "$(printf '%s' "$output" | cdata_escape)"
  printf "</entry>\n"
}

# fetch - Download a GitHub repository and return its local path
#
# Usage:
#   fetch github://owner/repo              Download default branch
#   fetch github://owner/repo@branch       Download specific branch
#
# Exits on failure.
fetch() {
  local url="$1"

  if [[ ! "$url" =~ ^github://(.+) ]]; then
    echo "$SCRIPT_NAME: fetch: unsupported URL scheme: $url" >&2
    exit 1
  fi

  local repo_spec="${BASH_REMATCH[1]}"
  local repo branch="main"

  if [[ "$repo_spec" =~ ^(.+)@(.+)$ ]]; then
    repo="${BASH_REMATCH[1]}"
    branch="${BASH_REMATCH[2]}"
  else
    repo="$repo_spec"
  fi

  local archive_url="https://github.com/${repo}/archive/refs/heads/${branch}.tar.gz"
  local extract_dir
  extract_dir=$(mktemp -d "$BUILD_DIR/fetch.XXXXXXXXXX")

  if ! curl -fsSL "$archive_url" | tar -xzf - -C "$extract_dir" --strip-components=1; then
    echo "$SCRIPT_NAME: fetch: failed to download $archive_url" >&2
    exit 1
  fi

  echo "$extract_dir"
}

# Get list of dynamic topics
get_dynamic_topics() {
  if [[ -d "$CONTEXT_BASE_DIR" ]]; then
    find "$CONTEXT_BASE_DIR" -mindepth 1 -maxdepth 1 \( -type d -o -type l \) -exec basename {} \; | sort
  fi
}

clean_url() {
  local u="$1"
  # Replace all // with /
  u="${u//\/\//\/}"
  # Fix protocol (restore https://)
  u="${u/https:\//https:\/\/}"
  echo "$u"
}

run_dynamic_topic() {
  local topic="$1"
  local topic_dir="$CONTEXT_BASE_DIR/$topic"

  # Check if directory exists (handles broken symlinks)
  if [[ ! -e "$topic_dir" ]]; then
    echo "$SCRIPT_NAME: topic '$topic' not found (or broken symlink at $topic_dir)" >&2
    exit 1
  fi

  if [[ ! -d "$topic_dir" ]]; then
    echo "$SCRIPT_NAME: topic '$topic' is not a directory" >&2
    exit 1
  fi

  # Find files
  find -L "$topic_dir" -type f \( -name "*.txt" -o -name "*.md" \) | sort | while read -r file; do
    local rel="${file#"$topic_dir"/}"
    local display_cmd

    case "$topic" in
      dac-*)
        local path
        # Use realpath if available, otherwise python fallback (robustness)
        # Assuming realpath is available per instructions
        path=$(realpath "$file")

        # Define markers to check against path
        local markers=(
          "/knowledge_base/latest/android"
        )
        local marker=""
        local suffix=""

        # Check markers in order
        for m in "${markers[@]}"; do
            if [[ "$path" == *"$m"* ]]; then
                marker="$m"
                break
            fi
        done
        
        if [[ -n "$marker" ]]; then
            suffix="${path#*"$marker"}"
        else
            suffix="/$rel"
        fi
        
        local base_url="https://developer.android.com"
        
        # Strip leading slash
        suffix="${suffix#/}"
        
        local published="$base_url/$suffix"
        local raw_url="$base_url/$suffix" # Raw matches published structure initially
        
        # Extension stripping
        if [[ "$published" == *.md.txt ]]; then
          published="${published%.md.txt}"
        elif [[ "$published" == *.txt ]]; then
          published="${published%.txt}"
        elif [[ "$published" == *.md ]]; then
          published="${published%.md}"
        fi
        
        # Index handling
        if [[ "$(basename "$published")" == "index" ]]; then
          published="$(dirname "$published")"
          if [[ "$published" == "." ]]; then published=""; fi
        fi
        
        raw_url=$(clean_url "$raw_url")
        published=$(clean_url "$published")
        # Remove trailing slash
        published="${published%/}"
        
        display_cmd="curl -s $raw_url # web page: $published"
        ;;
      *)
        display_cmd="cat $topic_dir/$rel"
        ;;
    esac

    run "$display_cmd" cat "$file"
  done
}

# =============================================================================
# TOPIC DEFINITIONS
# =============================================================================

topic_gemini_api() {
  local repo
  repo=$(fetch "github://google-gemini/cookbook")

  # Notebooks - clear outputs and execution counts
  local nb colab
  for nb in \
    "examples/Book_illustration.ipynb" \
    "examples/json_capabilities/Entity_Extraction_JSON.ipynb" \
    "examples/prompting/Basic_Evaluation.ipynb" \
    "examples/prompting/Basic_Information_Extraction.ipynb" \
    "quickstarts/Caching.ipynb" \
    "quickstarts/Counting_Tokens.ipynb" \
    "quickstarts/Error_handling.ipynb" \
    "quickstarts/Get_Started_Nano_Banana.ipynb" \
    "quickstarts/Image_out.ipynb" \
    "quickstarts/JSON_mode.ipynb" \
    "quickstarts/Safety.ipynb" \
    "quickstarts/System_instructions.ipynb"; do
    colab="https://colab.research.google.com/github/google-gemini/cookbook/blob/main/$nb"
    run "curl -s 'https://raw.githubusercontent.com/google-gemini/cookbook/main/$nb'  # web page: $colab" \
      jq '.cells[] |= (if .cell_type == "code" then .outputs = [] | .execution_count = null else . end)' "$repo/$nb"
  done

  # Documentation URLs
  local url
  for url in \
    "https://ai.google.dev/gemini-api/docs/caching.md.txt" \
    "https://ai.google.dev/gemini-api/docs/files.md.txt" \
    "https://ai.google.dev/gemini-api/docs/imagen.md.txt" \
    "https://ai.google.dev/gemini-api/docs/image-generation.md.txt" \
    "https://ai.google.dev/gemini-api/docs/image-understanding.md.txt" \
    "https://ai.google.dev/gemini-api/docs/long-context.md.txt" \
    "https://ai.google.dev/gemini-api/docs/models.md.txt" \
    "https://ai.google.dev/gemini-api/docs/pricing.md.txt" \
    "https://ai.google.dev/gemini-api/docs/prompting-strategies.md.txt" \
    "https://ai.google.dev/gemini-api/docs/rate-limits.md.txt" \
    "https://ai.google.dev/gemini-api/docs/safety-settings.md.txt" \
    "https://ai.google.dev/gemini-api/docs/structured-output.md.txt" \
    "https://ai.google.dev/gemini-api/docs/text-generation.md.txt" \
    "https://ai.google.dev/gemini-api/docs/tokens.md.txt" \
    "https://ai.google.dev/gemini-api/docs/troubleshooting.md.txt"; do
    run "curl -sfS '$url'" curl -sfS "$url"
  done
}

topic_mcp_server() {
  local repo
  repo=$(fetch "github://modelcontextprotocol/modelcontextprotocol")

  # Specific doc files
  local file slug published
  for file in \
    "docs/docs/learn/server-concepts.mdx" \
    "docs/docs/learn/architecture.mdx" \
    "docs/docs/develop/build-server.mdx"; do
    slug="${file#docs/docs/}"
    slug="${slug%.mdx}"
    published="https://modelcontextprotocol.io/docs/$slug"
    run "curl -s 'https://raw.githubusercontent.com/modelcontextprotocol/modelcontextprotocol/main/$file'  # web page: $published" cat "$repo/$file"
  done

  # Specification directory
  # Note: Excluding schema.mdx (~450KB) to save context.
  # It is available at: https://modelcontextprotocol.io/docs/specification/2025-11-25/schema
  find "$repo/docs/specification/2025-11-25" -name "*.mdx" -type f | grep -v "schema.mdx" | sort | while read -r file; do
    local rel="${file#"$repo"/}"
    local slug="${rel#docs/}"
    slug="${slug%.mdx}"
    local published="https://modelcontextprotocol.io/$slug"
    run "curl -s 'https://raw.githubusercontent.com/modelcontextprotocol/modelcontextprotocol/main/$rel'  # web page: $published" cat "$file"
  done
}

topic_gemini_cli() {
  local repo
  repo=$(fetch "github://google-gemini/gemini-cli")

  # Process all files in docs/, excluding legacy configuration
  find "$repo/docs" -name "*.md" -type f |
    grep -v "configuration-v1.md" |
    sort | while read -r file; do
    local rel="${file#"$repo"/}"
    local published="https://geminicli.com/${rel%.md}/"

    # Special handling for changelogs if needed, or just standard URL mapping
    # The original implementation for changelogs fetched from raw URLs directly in some cases,
    # but the find command here will cover them if they are in the repo.
    # The previous topic_gemini_cli_changelog used explicit URLs for index/latest/preview.
    # We'll rely on the repo content here which is generally better.

    run "curl -s 'https://raw.githubusercontent.com/google-gemini/gemini-cli/main/$rel'  # web page: $published" cat "$file"
  done
}

topic_inkyframe() {
  local inky pico
  inky=$(fetch "github://pimoroni/inky-frame")
  pico=$(fetch "github://pimoroni/pimoroni-pico")

  # inky-frame README
  if [[ -f "$inky/README.md" ]]; then
    run "curl -s 'https://raw.githubusercontent.com/pimoroni/inky-frame/main/README.md'" cat "$inky/README.md"
  fi

  # inky-frame docs, examples, modules
  local dir
  for dir in docs examples modules; do
    find "$inky/$dir" \( -name "*.md" -o -name "*.py" \) -type f 2>/dev/null | sort | while read -r file; do
      local rel="${file#"$inky"/}"
      run "curl -s 'https://raw.githubusercontent.com/pimoroni/inky-frame/main/$rel'" cat "$file"
    done
  done

  # pimoroni-pico picographics
  find "$pico/micropython/modules/picographics" -name "*.md" -type f | sort | while read -r file; do
    local rel="${file#"$pico"/}"
    run "curl -s 'https://raw.githubusercontent.com/pimoroni/pimoroni-pico/main/$rel'" cat "$file"
  done

  # pimoroni-pico inky_frame examples
  find "$pico/micropython/examples/inky_frame" \( -name "*.md" -o -name "*.py" \) -type f 2>/dev/null | sort | while read -r file; do
    local rel="${file#"$pico"/}"
    run "curl -s 'https://raw.githubusercontent.com/pimoroni/pimoroni-pico/main/$rel'" cat "$file"
  done

  # External URLs
  run "curl -sfS 'https://docs.micropython.org/en/latest/_sources/reference/mpremote.rst.txt'" \
    curl -sfS 'https://docs.micropython.org/en/latest/_sources/reference/mpremote.rst.txt'

  # Jina reader for learn.pimoroni.com (display URL differs from fetch URL)
  run "curl -s 'https://learn.pimoroni.com/article/getting-started-with-inky-frame'" \
    curl -sfS 'https://r.jina.ai/https://learn.pimoroni.com/article/getting-started-with-inky-frame'
}

topic_rpi() {
  local repo
  repo=$(fetch "github://raspberrypi/documentation@master")

  local src="$repo/documentation/asciidoc/computers"

  local dir published
  for dir in config_txt configuration getting-started os raspberry-pi remote-access; do
    published="https://www.raspberrypi.com/documentation/computers/${dir}.html"
    # Index file
    if [[ -f "$src/$dir.adoc" ]]; then
      run "curl -s 'https://raw.githubusercontent.com/raspberrypi/documentation/master/documentation/asciidoc/computers/$dir.adoc'  # web page: $published" cat "$src/$dir.adoc"
    fi
    # Directory contents
    if [[ -d "$src/$dir" ]]; then
      find "$src/$dir" -name "*.adoc" -type f | grep -v "device-tree.adoc" | sort | while read -r file; do
        local rel="${file#"$repo"/}"
        run "curl -s 'https://raw.githubusercontent.com/raspberrypi/documentation/master/$rel'  # web page: $published" cat "$file"
      done
    fi
  done

  # Standalone file
  if [[ -f "$src/software-sources.adoc" ]]; then
    run "curl -s 'https://raw.githubusercontent.com/raspberrypi/documentation/master/documentation/asciidoc/computers/software-sources.adoc'  # web page: https://www.raspberrypi.com/documentation/computers/software-sources.html" cat "$src/software-sources.adoc"
  fi
}

topic_skills() {
  # agentskills/agentskills repository - all .mdx files
  local agentskills
  agentskills=$(fetch "github://agentskills/agentskills")
  find "$agentskills" -name "*.mdx" -type f | sort | while read -r file; do
    local rel="${file#"$agentskills"/}"
    local slug="${rel#docs/}"
    slug="${slug%.mdx}"
    local published="https://agentskills.io/$slug"
    run "curl -s 'https://raw.githubusercontent.com/agentskills/agentskills/main/$rel'  # web page: $published" cat "$file"
  done

  # Claude Code documentation
  run "curl -sfS 'https://code.claude.com/docs/en/skills.md'  # web page: https://code.claude.com/docs/en/skills" \
    curl -sfS 'https://code.claude.com/docs/en/skills.md'

  # Claude platform overview
  run "curl -sfS 'https://platform.claude.com/docs/en/agents-and-tools/agent-skills/overview.md'  # web page: https://platform.claude.com/docs/en/agents-and-tools/agent-skills/overview" \
    curl -sfS 'https://platform.claude.com/docs/en/agents-and-tools/agent-skills/overview.md'

  # Claude platform best practices
  run "curl -sfS 'https://platform.claude.com/docs/en/agents-and-tools/agent-skills/best-practices.md'  # web page: https://platform.claude.com/docs/en/agents-and-tools/agent-skills/best-practices" \
    curl -sfS 'https://platform.claude.com/docs/en/agents-and-tools/agent-skills/best-practices.md'

  # Anthropic skills repository
  run "curl -sfS 'https://raw.githubusercontent.com/anthropics/skills/refs/heads/main/skills/skill-creator/SKILL.md'" \
    curl -sfS 'https://raw.githubusercontent.com/anthropics/skills/refs/heads/main/skills/skill-creator/SKILL.md'

  # Gemini CLI skills
  run "curl -sfS 'https://raw.githubusercontent.com/google-gemini/gemini-cli/main/docs/cli/skills.md'  # web page: https://geminicli.com/docs/cli/skills/" \
    curl -sfS 'https://raw.githubusercontent.com/google-gemini/gemini-cli/main/docs/cli/skills.md'

  # OpenAI Codex skills
  run "curl -sfS 'https://developers.openai.com/codex/skills.md'  # web page: https://developers.openai.com/codex/skills/" \
    curl -sfS 'https://developers.openai.com/codex/skills.md'
  run "curl -sfS 'https://developers.openai.com/api/docs/guides/tools-skills.md'  # web page: https://developers.openai.com/api/docs/guides/tools-skills/" \
    curl -sfS 'https://developers.openai.com/api/docs/guides/tools-skills.md'
}

topic_homeassistant() {
  local ha_io dev_docs
  ha_io=$(fetch "github://home-assistant/home-assistant.io@current")
  dev_docs=$(fetch "github://home-assistant/developers.home-assistant@master")

  # Integration docs
  local integration published
  for integration in \
    binary_sensor \
    climate \
    derivative \
    esphome \
    hassio \
    home_connect \
    homeassistant \
    input_boolean \
    input_datetime \
    input_number \
    matter \
    metoffice \
    min_max \
    mqtt \
    nest \
    openweathermap \
    recorder \
    ruuvitag_ble \
    sensor \
    shelly \
    sql \
    statistics \
    switch_as_x \
    template \
    threshold \
    utility_meter \
    vicare \
    water_heater; do
    published="https://www.home-assistant.io/integrations/$integration/"
    run "curl -s 'https://raw.githubusercontent.com/home-assistant/home-assistant.io/current/source/_integrations/$integration.markdown'  # web page: $published" \
      cat "$ha_io/source/_integrations/$integration.markdown"
  done

  # Automation docs
  local doc slug
  for doc in trigger condition action templating; do
    published="https://www.home-assistant.io/docs/automation/$doc/"
    run "curl -s 'https://raw.githubusercontent.com/home-assistant/home-assistant.io/current/source/_docs/automation/$doc.markdown'  # web page: $published" \
      cat "$ha_io/source/_docs/automation/$doc.markdown"
  done

  # Script docs
  for doc in scripts scripts/conditions scripts/perform-actions; do
    slug="${doc%.markdown}"
    published="https://www.home-assistant.io/docs/$slug/"
    run "curl -s 'https://raw.githubusercontent.com/home-assistant/home-assistant.io/current/source/_docs/$doc.markdown'  # web page: $published" \
      cat "$ha_io/source/_docs/$doc.markdown"
  done

  # Configuration and templating docs
  for doc in configuration/yaml configuration/templating; do
    published="https://www.home-assistant.io/docs/$doc/"
    run "curl -s 'https://raw.githubusercontent.com/home-assistant/home-assistant.io/current/source/_docs/$doc.markdown'  # web page: $published" \
      cat "$ha_io/source/_docs/$doc.markdown"
  done

  # REST API and WebSocket API (from developers.home-assistant)
  local api_file api_slug
  for api_file in rest.md websocket.md supervisor/endpoints.md supervisor/models.md; do
    api_slug="${api_file%.md}"
    published="https://developers.home-assistant.io/docs/api/$api_slug"
    run "curl -s 'https://raw.githubusercontent.com/home-assistant/developers.home-assistant/master/docs/api/$api_file'  # web page: $published" \
      cat "$dev_docs/docs/api/$api_file"
  done

  # Apps documentation (from developers.home-assistant)
  local apps_file apps_slug
  for apps_file in communication.md configuration.md presentation.md publishing.md repository.md security.md testing.md tutorial.md; do
    apps_slug="${apps_file%.md}"
    published="https://developers.home-assistant.io/docs/apps/$apps_slug"
    run "curl -s 'https://raw.githubusercontent.com/home-assistant/developers.home-assistant/master/docs/apps/$apps_file'  # web page: $published" \
      cat "$dev_docs/docs/apps/$apps_file"
  done
}

topic_gemini_sdk_js() {
  run "curl -sfS 'https://raw.githubusercontent.com/googleapis/js-genai/main/codegen_instructions.md'" \
    curl -sfS 'https://raw.githubusercontent.com/googleapis/js-genai/main/codegen_instructions.md'
}

# =============================================================================
# TOPIC REGISTRY
# =============================================================================

TOPICS=(
  "gemini-api:Gemini API documentation and examples"
  "mcp-server:MCP server documentation and specification"
  "gemini-cli:Gemini CLI documentation"
  "inkyframe:Pimoroni Inky Frame documentation"
  "rpi:Raspberry Pi documentation"
  "skills:Agent skills documentation (Claude, Gemini CLI, OpenAI Codex)"
  "homeassistant:Home Assistant integration, automation, API and CLI documentation"
  "gemini-sdk-js:Google Gemini JavaScript SDK codegen instructions"
)

# =============================================================================
# USAGE AND ARGUMENT PARSING
# =============================================================================

usage() {
  cat <<EOF
Usage: $SCRIPT_NAME <topic>

Generate aggregated context for a specific topic. Output is written to stdout
as a shell_session XML format suitable for AI agent consumption.

Topics:
EOF
  for entry in "${TOPICS[@]}"; do
    local name="${entry%%:*}"
    local desc="${entry#*:}"
    printf "  %-22s %s\n" "$name" "$desc"
  done

  echo ""
  echo "Dynamic Topics ($CONTEXT_BASE_DIR):"
  local dynamics
  # Read into array to handle empty case safely
  read -r -a dynamics <<<"$(get_dynamic_topics | tr '\n' ' ')"
  if [[ ${#dynamics[@]} -eq 0 || -z "${dynamics[0]}" ]]; then
    echo "  (none)"
  else
    for topic in "${dynamics[@]}"; do
      if [[ -n "$topic" ]]; then
        echo "  $topic"
      fi
    done
  fi

  cat <<EOF

Options:
  -h, --help    Display this help message and exit
  -f, --force   Force cache rebuild (ignore 24h cache)
  --list        List available topics (names only)

Examples:
  $SCRIPT_NAME gemini-api
    Generate Gemini API context to stdout

  $SCRIPT_NAME gemini-api > gemini-api-context.xml
    Save context to a file

  $SCRIPT_NAME gemini-api | pbcopy
    Copy context to clipboard (macOS)
EOF
  exit 0
}

list_topics() {
  for entry in "${TOPICS[@]}"; do
    echo "${entry%%:*}"
  done
  get_dynamic_topics
  exit 0
}

emit_header() {
  local topic_desc="$1"
  local timestamp
  timestamp=$(date +%Y-%m-%dT%H:%M:%S%z)
  echo "<shell_session>"
  cat <<EOF
<context_summary>
  <generated_at>$timestamp</generated_at>
  <purpose>
    Topic: $topic_desc

    This content represents a recorded shell session designed to provide context for an AI agent.
    It aggregates resources (local files, remote URLs, system info) by capturing shell commands
    and their output.
  </purpose>
  <structure>
    The session is organized as a sequence of &lt;entry&gt; elements:
    1. &lt;command&gt;: The command string acting as the data source. (e.g., "cat file.txt" or "curl url")
       Treat this as the source of truth for where the data originated.
    2. &lt;output&gt;: The raw content returned by that command.
  </structure>
  <guidelines>
    - PROVENANCE: The &lt;command&gt; element indicates an approximate source for the data. In some cases
      the actual retrieval method may differ (e.g., fetched from a local cache or extracted archive).
    - SNAPSHOT: Outputs represent a best-effort snapshot at the time this script was run.
  </guidelines>
</context_summary>
EOF
}

emit_footer() {
  echo "</shell_session>"
}

# =============================================================================
# MAIN
# =============================================================================

FORCE_REFRESH=false
TOPIC=""

while [[ $# -gt 0 ]]; do
  case "$1" in
    -h | --help)
      usage
      ;;
    --list)
      list_topics
      ;;
    -f | --force)
      FORCE_REFRESH=true
      shift
      ;;
    -*)
      echo "$SCRIPT_NAME: unknown option: $1" >&2
      exit 1
      ;;
    *)
      if [[ -n "$TOPIC" ]]; then
        echo "$SCRIPT_NAME: only one topic allowed" >&2
        exit 1
      fi
      TOPIC="$1"
      shift
      ;;
  esac
done

if [[ -z "$TOPIC" ]]; then
  usage
fi

# Validate topic
TOPIC_FUNC="topic_${TOPIC//-/_}"
IS_DYNAMIC=false

if declare -f "$TOPIC_FUNC" >/dev/null 2>&1; then
  IS_DYNAMIC=false
else
  # Check if it's a dynamic topic
  DYNAMIC_DIR="$CONTEXT_BASE_DIR/$TOPIC"
  if [[ -d "$DYNAMIC_DIR" ]]; then # check for directory existence (following symlinks for -d)
    IS_DYNAMIC=true
  elif [[ -L "$DYNAMIC_DIR" ]]; then
     # It is a symlink but -d failed, likely broken
     # We let run_dynamic_topic fail with a good message later, OR fail here.
     # The prompt says "error when context topic is called".
     # Since run_dynamic_topic handles it, we can mark it as dynamic here.
     IS_DYNAMIC=true
  else
    echo "$SCRIPT_NAME: unknown topic: $TOPIC" >&2
    echo "Run '$SCRIPT_NAME --list' to see available topics" >&2
    exit 1
  fi
fi

# Check dependencies
require curl
require jq
# Cache setup
CACHE_DIR="${XDG_CACHE_HOME:-$HOME/.cache}/context"
mkdir -p "$CACHE_DIR"
CACHE_FILE="$CACHE_DIR/$TOPIC.xml"

# Check cache
if [[ "$FORCE_REFRESH" == "false" && -f "$CACHE_FILE" ]]; then
  # Resolve script path for modification check
  SCRIPT_PATH="$0"
  if [[ ! -f "$SCRIPT_PATH" ]]; then
    # Fallback if $0 is just the basename (e.g. found in PATH)
    SCRIPT_PATH=$(command -v "$0" || echo "")
  fi

  # Check if cache is fresh:
  # 1. Less than 24 hours old (find -mtime -1)
  # 2. Newer than the script itself (if script found)
  if [[ -n "$(find "$CACHE_FILE" -mtime -1 2>/dev/null)" ]]; then
    if [[ -z "$SCRIPT_PATH" || "$CACHE_FILE" -nt "$SCRIPT_PATH" ]]; then
      cat "$CACHE_FILE"
      exit 0
    fi
  fi
fi

# Create build directory
BUILD_DIR=$(mktemp -d "${TMPDIR:-/tmp}/$SCRIPT_NAME.XXXXXXXXXX")
trap 'rm -rf "$BUILD_DIR"' EXIT

# Look up topic description
TOPIC_DESC=""
if [[ "$IS_DYNAMIC" == "true" ]]; then
  TOPIC_DESC="Dynamic topic: $TOPIC"
else
  for entry in "${TOPICS[@]}"; do
    if [[ "${entry%%:*}" == "$TOPIC" ]]; then
      TOPIC_DESC="${entry#*:}"
      break
    fi
  done
fi

# Output generation
OUTPUT_FILE="$BUILD_DIR/output.xml"

{
  emit_header "$TOPIC_DESC"
  if [[ "$IS_DYNAMIC" == "true" ]]; then
    run_dynamic_topic "$TOPIC"
  else
    "$TOPIC_FUNC"
  fi
  emit_footer
} >"$OUTPUT_FILE"

# Check output size (3MB limit)
SIZE=$(wc -c <"$OUTPUT_FILE" | tr -d ' \t')
if ((SIZE > 3000000)); then
  echo "$SCRIPT_NAME: warning: output size ($SIZE bytes) exceeds 3MB" >&2
fi

# Update cache
cp "$OUTPUT_FILE" "$CACHE_FILE"

cat "$OUTPUT_FILE"
