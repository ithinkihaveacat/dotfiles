#!/usr/bin/env bash

# context - Generate aggregated context for various topics
#
# Each topic is a bash function that uses fetch() to download sources
# and run() to output content in a shell_session XML format.

set -e

SCRIPT_NAME=$(basename "$0")

# =============================================================================
# HELPER FUNCTIONS
# =============================================================================

require() {
  hash "$@" || {
    echo "$SCRIPT_NAME: command '$1' not found" >&2
    exit 127
  }
}

xml_escape() {
  python3 -c 'import sys, html; print(html.escape(sys.stdin.read()), end="")'
}

cdata_escape() {
  python3 -c '
import sys
d = sys.stdin.read()
d = d.translate({i: None for i in range(32) if i not in (9, 10, 13)})
print(d.replace("]]>", "]]]]><![CDATA[>"), end="")
'
}

# is_binary - returns 0 if input contains null bytes (binary), 1 if text
is_binary() {
  grep -q $'\x00'
}

# run DISPLAY_CMD [SOURCE_CMD]
#
# Captures a command and its output as XML. The first argument is displayed
# in the <command> element. The second argument, if provided, is the command
# actually executed to produce the output; if omitted, it defaults to DISPLAY_CMD.
#
# This allows showing a canonical or remote command while executing a local
# equivalent. For example, if foo.txt exists locally but the intended source
# is a remote URL:
#
#   run "curl -s https://example.com/foo.txt" "cat foo.txt"
#
# This displays "curl -s https://example.com/foo.txt" but outputs the contents
# of the local file.
#
# Errors (non-zero exit, binary content) emit an <error> entry instead of
# <entry> and processing continues.
run() {
  local display_cmd="$1"
  local source_cmd="${2:-$1}"
  local output status

  output=$(eval "$source_cmd" 2>/dev/null)
  status=$?

  if [[ $status -ne 0 ]]; then
    printf "<error>\n"
    printf "<command>%s</command>\n" "$(printf '%s' "$display_cmd" | xml_escape)"
    printf "<message>Command failed with exit status %d</message>\n" "$status"
    printf "</error>\n"
    return
  fi

  if printf '%s' "$output" | is_binary; then
    printf "<error>\n"
    printf "<command>%s</command>\n" "$(printf '%s' "$display_cmd" | xml_escape)"
    printf "<message>Binary content detected</message>\n"
    printf "</error>\n"
    return
  fi

  printf "<entry>\n"
  printf "<command>%s</command>\n" "$(printf '%s' "$display_cmd" | xml_escape)"
  printf "<output><![CDATA[%s]]></output>\n" "$(printf '%s' "$output" | cdata_escape)"
  printf "</entry>\n"
}

# fetch - Download a source and return its local path
#
# Usage:
#   fetch github://owner/repo              Download default branch, return dir path
#   fetch github://owner/repo@branch       Download specific branch, return dir path
#   fetch https://example.com/file.txt     Download URL, return file path
#
# All downloads are cached in $BUILD_DIR for the duration of the script.
fetch() {
  local url="$1"

  if [[ "$url" =~ ^github://(.+) ]]; then
    local repo_spec="${BASH_REMATCH[1]}"
    local repo branch="main"

    # Parse owner/repo@branch
    if [[ "$repo_spec" =~ ^(.+)@(.+)$ ]]; then
      repo="${BASH_REMATCH[1]}"
      branch="${BASH_REMATCH[2]}"
    else
      repo="$repo_spec"
    fi

    local repo_slug="${repo//\//-}"
    local extract_dir="$BUILD_DIR/repos/$repo_slug"

    if [[ ! -d "$extract_dir" ]]; then
      local archive_url="https://github.com/${repo}/archive/refs/heads/${branch}.zip"
      local zip_file="$BUILD_DIR/${repo_slug}.zip"
      local archive_name="${repo##*/}-${branch}"

      curl -fsSL -o "$zip_file" "$archive_url"
      mkdir -p "$extract_dir"
      unzip -o -q "$zip_file" -d "$BUILD_DIR/temp_extract"
      mv "$BUILD_DIR/temp_extract/$archive_name"/* "$extract_dir/"
      rm -rf "$BUILD_DIR/temp_extract" "$zip_file"
    fi

    echo "$extract_dir"

  elif [[ "$url" =~ ^https?:// ]]; then
    local filename
    filename=$(basename "$url")
    local dest="$BUILD_DIR/urls/$filename"

    if [[ ! -f "$dest" ]]; then
      mkdir -p "$BUILD_DIR/urls"
      curl -fsSL -o "$dest" "$url"
    fi

    echo "$dest"

  else
    echo "$SCRIPT_NAME: fetch: unsupported URL scheme: $url" >&2
    return 1
  fi
}

# run_url - Fetch a URL and output its content
#
# Usage: run_url URL
#
# Convenience wrapper that fetches a URL and runs it with proper display.
run_url() {
  local url="$1"
  local file
  file=$(fetch "$url")
  run "curl -s '$url'" "cat '$file'"
}

# run_repo_file - Output a file from a fetched repo with proper URL display
#
# Usage: run_repo_file OWNER/REPO BRANCH LOCAL_REPO_PATH FILE_PATH
#
# Displays as: curl -s https://raw.githubusercontent.com/owner/repo/branch/path
# Executes: cat local_repo_path/path
run_repo_file() {
  local repo="$1"
  local branch="$2"
  local repo_path="$3"
  local file_path="$4"
  local url="https://raw.githubusercontent.com/${repo}/${branch}/${file_path}"
  run "curl -s '$url'" "cat '$repo_path/$file_path'"
}

# run_repo_tree - Output all matching files from a repo directory
#
# Usage: run_repo_tree OWNER/REPO BRANCH LOCAL_REPO_PATH DIR_PATH [GLOB_PATTERN]
#
# Iterates through files matching the pattern and outputs each one.
run_repo_tree() {
  local repo="$1"
  local branch="$2"
  local repo_path="$3"
  local dir_path="$4"
  local glob_pattern="${5:-*}"

  find "$repo_path/$dir_path" -name "$glob_pattern" -type f 2>/dev/null | sort | while read -r file; do
    local rel_path="${file#$repo_path/}"
    run_repo_file "$repo" "$branch" "$repo_path" "$rel_path"
  done
}

# filter_ipynb - Filter binary image data from Jupyter notebooks
#
# Usage: filter_ipynb INPUT
# Outputs filtered JSON to stdout
filter_ipynb() {
  local input="$1"
  jq 'walk(if type == "object" and has("data") and (.data | type == "object") then
    .data |= with_entries(select(.key | test("^image/") | not))
    else . end) |
    walk(if type == "object" and has("outputs") then
    .outputs |= map(if .data then .data |= with_entries(select(.key | test("^image/") | not)) else . end)
    else . end)' "$input"
}

# run_notebook - Output a filtered Jupyter notebook
#
# Usage: run_notebook OWNER/REPO BRANCH LOCAL_REPO_PATH NOTEBOOK_PATH
run_notebook() {
  local repo="$1"
  local branch="$2"
  local repo_path="$3"
  local notebook_path="$4"
  local url="https://raw.githubusercontent.com/${repo}/${branch}/${notebook_path}"

  local output status
  output=$(filter_ipynb "$repo_path/$notebook_path" 2>/dev/null)
  status=$?

  if [[ $status -ne 0 ]]; then
    printf "<error>\n"
    printf "<command>%s</command>\n" "$(printf '%s' "curl -s '$url'" | xml_escape)"
    printf "<message>Failed to process notebook</message>\n"
    printf "</error>\n"
    return
  fi

  printf "<entry>\n"
  printf "<command>%s</command>\n" "$(printf '%s' "curl -s '$url'" | xml_escape)"
  printf "<output><![CDATA[%s]]></output>\n" "$(printf '%s' "$output" | cdata_escape)"
  printf "</entry>\n"
}

# =============================================================================
# TOPIC DEFINITIONS
# =============================================================================

topic_gemini_api() {
  local repo
  repo=$(fetch "github://google-gemini/cookbook")

  # Notebooks (filtered to remove binary image data)
  run_notebook "google-gemini/cookbook" "main" "$repo" "examples/Book_illustration.ipynb"
  run_notebook "google-gemini/cookbook" "main" "$repo" "quickstarts/Image_out.ipynb"

  # Documentation URLs
  run_url "https://ai.google.dev/gemini-api/docs/image-generation.md.txt"
  run_url "https://ai.google.dev/gemini-api/docs/image-understanding.md.txt"
  run_url "https://ai.google.dev/gemini-api/docs/models.md.txt"
  run_url "https://ai.google.dev/gemini-api/docs/prompting-strategies.md.txt"
  run_url "https://ai.google.dev/gemini-api/docs/structured-output.md.txt"
  run_url "https://ai.google.dev/gemini-api/docs/text-generation.md.txt"
}

topic_gemini_sdk() {
  local repo
  repo=$(fetch "github://googleapis/js-genai")

  run_repo_tree "googleapis/js-genai" "main" "$repo" "src"
}

topic_mcp_server() {
  local repo
  repo=$(fetch "github://modelcontextprotocol/modelcontextprotocol")

  run_repo_file "modelcontextprotocol/modelcontextprotocol" "main" "$repo" "docs/docs/learn/server-concepts.mdx"
  run_repo_file "modelcontextprotocol/modelcontextprotocol" "main" "$repo" "docs/docs/learn/architecture.mdx"
  run_repo_tree "modelcontextprotocol/modelcontextprotocol" "main" "$repo" "docs/specification/2025-11-25"
}

topic_mcp_typescript_sdk() {
  local repo
  repo=$(fetch "github://modelcontextprotocol/typescript-sdk")

  run_repo_file "modelcontextprotocol/typescript-sdk" "main" "$repo" "README.md"
}

topic_gemini_cli() {
  local repo
  repo=$(fetch "github://google-gemini/gemini-cli")

  run_repo_tree "google-gemini/gemini-cli" "main" "$repo" "docs"
}

topic_gemini_cli_extensions() {
  local repo
  repo=$(fetch "github://google-gemini/gemini-cli")

  run_repo_tree "google-gemini/gemini-cli" "main" "$repo" "docs/extensions" "*.md"
}

topic_gemini_cli_hooks() {
  local repo
  repo=$(fetch "github://google-gemini/gemini-cli")

  run_repo_tree "google-gemini/gemini-cli" "main" "$repo" "docs/hooks" "*.md"
}

topic_inkyframe() {
  local inky pico
  inky=$(fetch "github://pimoroni/inky-frame")
  pico=$(fetch "github://pimoroni/pimoroni-pico")

  run_repo_tree "pimoroni/inky-frame" "main" "$inky" "docs"
  run_repo_tree "pimoroni/inky-frame" "main" "$inky" "examples"
  run_repo_tree "pimoroni/inky-frame" "main" "$inky" "modules"
  run_repo_tree "pimoroni/pimoroni-pico" "main" "$pico" "micropython/modules/picographics"

  # External URLs
  run_url "https://docs.micropython.org/en/latest/_sources/reference/mpremote.rst.txt"

  # Jina reader for learn.pimoroni.com (rendered HTML)
  local pimoroni_learn
  pimoroni_learn=$(fetch "https://r.jina.ai/https://learn.pimoroni.com/article/getting-started-with-inky-frame")
  run "curl -s 'https://learn.pimoroni.com/article/getting-started-with-inky-frame'" "cat '$pimoroni_learn'"
}

topic_rpi() {
  local repo
  repo=$(fetch "github://raspberrypi/documentation@master")

  local src="$repo/documentation/asciidoc/computers"

  for dir in config_txt configuration getting-started os raspberry-pi remote-access; do
    # Index file
    if [[ -f "$src/$dir.adoc" ]]; then
      run_repo_file "raspberrypi/documentation" "master" "$repo" "documentation/asciidoc/computers/$dir.adoc"
    fi
    # Directory contents
    if [[ -d "$src/$dir" ]]; then
      run_repo_tree "raspberrypi/documentation" "master" "$repo" "documentation/asciidoc/computers/$dir"
    fi
  done

  # Additional standalone files
  if [[ -f "$src/software-sources.adoc" ]]; then
    run_repo_file "raspberrypi/documentation" "master" "$repo" "documentation/asciidoc/computers/software-sources.adoc"
  fi
}

topic_skills() {
  # 1. agentskills/agentskills repository - all .mdx files
  local agentskills_repo
  agentskills_repo=$(fetch "github://agentskills/agentskills")
  run_repo_tree "agentskills/agentskills" "main" "$agentskills_repo" "" "*.mdx"

  # 2. Claude platform best practices
  run_url "https://platform.claude.com/docs/en/agents-and-tools/agent-skills/best-practices.md"

  # 3. Anthropic skills repository - skill-creator SKILL.md
  run_url "https://raw.githubusercontent.com/anthropics/skills/refs/heads/main/skills/skill-creator/SKILL.md"

  # 4. Gemini CLI skills documentation
  run_url "https://raw.githubusercontent.com/google-gemini/gemini-cli/main/docs/cli/skills.md"

  # 5. OpenAI Codex skills documentation
  run_url "https://developers.openai.com/codex/skills.md"

  # 6. OpenAI Codex create-skill documentation
  run_url "https://developers.openai.com/codex/skills/create-skill.md"
}

# =============================================================================
# TOPIC REGISTRY
# =============================================================================

TOPICS=(
  "gemini-api:Gemini API documentation and examples"
  "gemini-sdk:Gemini TypeScript/JavaScript SDK"
  "mcp-server:MCP server documentation and specification"
  "mcp-typescript-sdk:MCP TypeScript SDK documentation"
  "gemini-cli:Gemini CLI documentation (all)"
  "gemini-cli-extensions:Gemini CLI extensions documentation"
  "gemini-cli-hooks:Gemini CLI hooks documentation"
  "inkyframe:Pimoroni Inky Frame documentation"
  "rpi:Raspberry Pi documentation"
  "skills:Agent skills documentation (Claude, Gemini CLI, OpenAI Codex)"
)

# =============================================================================
# USAGE AND ARGUMENT PARSING
# =============================================================================

usage() {
  cat <<EOF
Usage: $SCRIPT_NAME <topic>

Generate aggregated context for a specific topic. Output is written to stdout
as a shell_session XML format suitable for AI agent consumption.

Topics:
EOF
  for entry in "${TOPICS[@]}"; do
    local name="${entry%%:*}"
    local desc="${entry#*:}"
    printf "  %-22s %s\n" "$name" "$desc"
  done
  cat <<EOF

Options:
  -h, --help    Display this help message and exit
  --list        List available topics (names only)

Examples:
  $SCRIPT_NAME gemini-api
    Generate Gemini API context to stdout

  $SCRIPT_NAME gemini-api > gemini-api-context.xml
    Save context to a file

  $SCRIPT_NAME gemini-api | pbcopy
    Copy context to clipboard (macOS)
EOF
  exit 0
}

list_topics() {
  for entry in "${TOPICS[@]}"; do
    echo "${entry%%:*}"
  done
  exit 0
}

emit_header() {
  echo "<shell_session>"
  cat <<EOF
<context_summary>
  <purpose>
    This content represents a recorded shell session designed to provide context for an AI agent.
    It aggregates resources (local files, remote URLs, system info) by capturing shell commands
    and their output.
  </purpose>
  <structure>
    The session is organized as a sequence of &lt;entry&gt; elements:
    1. &lt;command&gt;: The command string acting as the data source. (e.g., "cat file.txt" or "curl url")
       Treat this as the source of truth for where the data originated.
    2. &lt;output&gt;: The raw content returned by that command.
    Errors appear as &lt;error&gt; elements with a &lt;message&gt; instead of &lt;output&gt;.
  </structure>
  <guidelines>
    - PROVENANCE: The origin of the data is defined by the command itself. If the command is
      \`curl -s https://example.com\`, the content is from that external URL.
    - SNAPSHOT: The outputs below capture the exact state of the resources at the time this script was run.
  </guidelines>
</context_summary>
EOF
}

emit_footer() {
  echo "</shell_session>"
}

# =============================================================================
# MAIN
# =============================================================================

if [[ $# -lt 1 ]]; then
  usage
fi

case "$1" in
  -h|--help)
    usage
    ;;
  --list)
    list_topics
    ;;
  -*)
    echo "$SCRIPT_NAME: unknown option: $1" >&2
    exit 1
    ;;
  *)
    TOPIC="$1"
    ;;
esac

# Validate topic
TOPIC_FUNC="topic_${TOPIC//-/_}"
if ! declare -f "$TOPIC_FUNC" > /dev/null 2>&1; then
  echo "$SCRIPT_NAME: unknown topic: $TOPIC" >&2
  echo "Run '$SCRIPT_NAME --list' to see available topics" >&2
  exit 1
fi

# Check dependencies
require curl
require unzip
require jq
require python3

# Create build directory
BUILD_DIR=$(mktemp -d "${TMPDIR:-/tmp}/$SCRIPT_NAME.XXXXXXXXXX")
trap 'rm -rf "$BUILD_DIR"' EXIT

# Output header
emit_header

# Run the topic function
"$TOPIC_FUNC"

# Output footer
emit_footer
