#!/usr/bin/env bash

# context - Generate aggregated context for various topics
#
# Each topic is a bash function that uses fetch() to download GitHub repos
# and run() to output content in a shell_session XML format.

set -eo pipefail

SCRIPT_NAME=$(basename "$0")

# =============================================================================
# HELPER FUNCTIONS
# =============================================================================

require() {
  hash "$@" || {
    echo "$SCRIPT_NAME: command '$1' not found" >&2
    exit 127
  }
}

xml_escape() {
  python3 -c 'import sys, html; print(html.escape(sys.stdin.read(), quote=False), end="")'
}

cdata_escape() {
  python3 -c '
import sys
d = sys.stdin.read()
d = d.translate({i: None for i in range(32) if i not in (9, 10, 13)})
print(d.replace("]]>", "]]]]><![CDATA[>"), end="")
'
}

# run DISPLAY_CMD COMMAND [ARGS...]
#
# Captures a command and its output as XML. The first argument is displayed
# in the <command> element. The remaining arguments are the command to execute.
# Exits on failure.
run() {
  local display_cmd="$1"
  shift
  local output

  if ! output=$("$@"); then
    echo "$SCRIPT_NAME: command failed: $display_cmd" >&2
    exit 1
  fi

  printf "<entry>\n"
  printf "<command>%s</command>\n" "$(printf '%s' "$display_cmd" | xml_escape)"
  printf "<output><![CDATA[%s]]></output>\n" "$(printf '%s' "$output" | cdata_escape)"
  printf "</entry>\n"
}

# fetch - Download a GitHub repository and return its local path
#
# Usage:
#   fetch github://owner/repo              Download default branch
#   fetch github://owner/repo@branch       Download specific branch
#
# Exits on failure.
fetch() {
  local url="$1"

  if [[ ! "$url" =~ ^github://(.+) ]]; then
    echo "$SCRIPT_NAME: fetch: unsupported URL scheme: $url" >&2
    exit 1
  fi

  local repo_spec="${BASH_REMATCH[1]}"
  local repo branch="main"

  if [[ "$repo_spec" =~ ^(.+)@(.+)$ ]]; then
    repo="${BASH_REMATCH[1]}"
    branch="${BASH_REMATCH[2]}"
  else
    repo="$repo_spec"
  fi

  local archive_url="https://github.com/${repo}/archive/refs/heads/${branch}.tar.gz"
  local extract_dir
  extract_dir=$(mktemp -d "$BUILD_DIR/fetch.XXXXXXXXXX")

  if ! curl -fsSL "$archive_url" | tar -xzf - -C "$extract_dir" --strip-components=1; then
    echo "$SCRIPT_NAME: fetch: failed to download $archive_url" >&2
    exit 1
  fi

  echo "$extract_dir"
}

# =============================================================================
# TOPIC DEFINITIONS
# =============================================================================

topic_gemini_api() {
  local repo
  repo=$(fetch "github://google-gemini/cookbook")

  # Notebooks - clear outputs and execution counts
  local nb colab
  for nb in \
    "examples/Book_illustration.ipynb" \
    "examples/json_capabilities/Entity_Extraction_JSON.ipynb" \
    "examples/prompting/Basic_Evaluation.ipynb" \
    "examples/prompting/Basic_Information_Extraction.ipynb" \
    "quickstarts/Caching.ipynb" \
    "quickstarts/Counting_Tokens.ipynb" \
    "quickstarts/Error_handling.ipynb" \
    "quickstarts/Get_Started_Nano_Banana.ipynb" \
    "quickstarts/Image_out.ipynb" \
    "quickstarts/JSON_mode.ipynb" \
    "quickstarts/Safety.ipynb" \
    "quickstarts/System_instructions.ipynb"; do
    colab="https://colab.research.google.com/github/google-gemini/cookbook/blob/main/$nb"
    run "curl -s 'https://raw.githubusercontent.com/google-gemini/cookbook/main/$nb'  # published to $colab" \
      jq '.cells[] |= (if .cell_type == "code" then .outputs = [] | .execution_count = null else . end)' "$repo/$nb"
  done

  # Documentation URLs
  local url
  for url in \
    "https://ai.google.dev/gemini-api/docs/caching.md.txt" \
    "https://ai.google.dev/gemini-api/docs/files.md.txt" \
    "https://ai.google.dev/gemini-api/docs/imagen.md.txt" \
    "https://ai.google.dev/gemini-api/docs/image-generation.md.txt" \
    "https://ai.google.dev/gemini-api/docs/image-understanding.md.txt" \
    "https://ai.google.dev/gemini-api/docs/long-context.md.txt" \
    "https://ai.google.dev/gemini-api/docs/models.md.txt" \
    "https://ai.google.dev/gemini-api/docs/pricing.md.txt" \
    "https://ai.google.dev/gemini-api/docs/prompting-strategies.md.txt" \
    "https://ai.google.dev/gemini-api/docs/rate-limits.md.txt" \
    "https://ai.google.dev/gemini-api/docs/safety-settings.md.txt" \
    "https://ai.google.dev/gemini-api/docs/structured-output.md.txt" \
    "https://ai.google.dev/gemini-api/docs/text-generation.md.txt" \
    "https://ai.google.dev/gemini-api/docs/tokens.md.txt" \
    "https://ai.google.dev/gemini-api/docs/troubleshooting.md.txt"; do
    run "curl -sfS '$url'" curl -sfS "$url"
  done
}

topic_mcp_server() {
  local repo
  repo=$(fetch "github://modelcontextprotocol/modelcontextprotocol")

  # Specific doc files
  local file slug published
  for file in \
    "docs/docs/learn/server-concepts.mdx" \
    "docs/docs/learn/architecture.mdx" \
    "docs/docs/develop/build-server.mdx"; do
    slug="${file#docs/docs/}"
    slug="${slug%.mdx}"
    published="https://modelcontextprotocol.io/docs/$slug"
    run "curl -s 'https://raw.githubusercontent.com/modelcontextprotocol/modelcontextprotocol/main/$file'  # published to $published" cat "$repo/$file"
  done

  # Specification directory
  # Note: Excluding schema.mdx (~450KB) to save context.
  # It is available at: https://modelcontextprotocol.io/docs/specification/2025-11-25/schema
  find "$repo/docs/specification/2025-11-25" -name "*.mdx" -type f | grep -v "schema.mdx" | sort | while read -r file; do
    local rel="${file#"$repo"/}"
    local slug="${rel#docs/}"
    slug="${slug%.mdx}"
    local published="https://modelcontextprotocol.io/$slug"
    run "curl -s 'https://raw.githubusercontent.com/modelcontextprotocol/modelcontextprotocol/main/$rel'  # published to $published" cat "$file"
  done
}

topic_gemini_cli() {
  local repo
  repo=$(fetch "github://google-gemini/gemini-cli")

  # Process all files in docs/, excluding legacy configuration
  find "$repo/docs" -name "*.md" -type f |
    grep -v "configuration-v1.md" |
    sort | while read -r file; do
    local rel="${file#"$repo"/}"
    local published="https://geminicli.com/${rel%.md}/"

    # Special handling for changelogs if needed, or just standard URL mapping
    # The original implementation for changelogs fetched from raw URLs directly in some cases,
    # but the find command here will cover them if they are in the repo.
    # The previous topic_gemini_cli_changelog used explicit URLs for index/latest/preview.
    # We'll rely on the repo content here which is generally better.

    run "curl -s 'https://raw.githubusercontent.com/google-gemini/gemini-cli/main/$rel'  # published to $published" cat "$file"
  done
}

topic_inkyframe() {
  local inky pico
  inky=$(fetch "github://pimoroni/inky-frame")
  pico=$(fetch "github://pimoroni/pimoroni-pico")

  # inky-frame README
  if [[ -f "$inky/README.md" ]]; then
    run "curl -s 'https://raw.githubusercontent.com/pimoroni/inky-frame/main/README.md'" cat "$inky/README.md"
  fi

  # inky-frame docs, examples, modules
  local dir
  for dir in docs examples modules; do
    find "$inky/$dir" \( -name "*.md" -o -name "*.py" \) -type f 2>/dev/null | sort | while read -r file; do
      local rel="${file#"$inky"/}"
      run "curl -s 'https://raw.githubusercontent.com/pimoroni/inky-frame/main/$rel'" cat "$file"
    done
  done

  # pimoroni-pico picographics
  find "$pico/micropython/modules/picographics" -name "*.md" -type f | sort | while read -r file; do
    local rel="${file#"$pico"/}"
    run "curl -s 'https://raw.githubusercontent.com/pimoroni/pimoroni-pico/main/$rel'" cat "$file"
  done

  # pimoroni-pico inky_frame examples
  find "$pico/micropython/examples/inky_frame" \( -name "*.md" -o -name "*.py" \) -type f 2>/dev/null | sort | while read -r file; do
    local rel="${file#"$pico"/}"
    run "curl -s 'https://raw.githubusercontent.com/pimoroni/pimoroni-pico/main/$rel'" cat "$file"
  done

  # External URLs
  run "curl -sfS 'https://docs.micropython.org/en/latest/_sources/reference/mpremote.rst.txt'" \
    curl -sfS 'https://docs.micropython.org/en/latest/_sources/reference/mpremote.rst.txt'

  # Jina reader for learn.pimoroni.com (display URL differs from fetch URL)
  run "curl -s 'https://learn.pimoroni.com/article/getting-started-with-inky-frame'" \
    curl -sfS 'https://r.jina.ai/https://learn.pimoroni.com/article/getting-started-with-inky-frame'
}

topic_rpi() {
  local repo
  repo=$(fetch "github://raspberrypi/documentation@master")

  local src="$repo/documentation/asciidoc/computers"

  local dir published
  for dir in config_txt configuration getting-started os raspberry-pi remote-access; do
    published="https://www.raspberrypi.com/documentation/computers/${dir}.html"
    # Index file
    if [[ -f "$src/$dir.adoc" ]]; then
      run "curl -s 'https://raw.githubusercontent.com/raspberrypi/documentation/master/documentation/asciidoc/computers/$dir.adoc'  # published to $published" cat "$src/$dir.adoc"
    fi
    # Directory contents
    if [[ -d "$src/$dir" ]]; then
      find "$src/$dir" -name "*.adoc" -type f | grep -v "device-tree.adoc" | sort | while read -r file; do
        local rel="${file#"$repo"/}"
        run "curl -s 'https://raw.githubusercontent.com/raspberrypi/documentation/master/$rel'  # published to $published" cat "$file"
      done
    fi
  done

  # Standalone file
  if [[ -f "$src/software-sources.adoc" ]]; then
    run "curl -s 'https://raw.githubusercontent.com/raspberrypi/documentation/master/documentation/asciidoc/computers/software-sources.adoc'  # published to https://www.raspberrypi.com/documentation/computers/software-sources.html" cat "$src/software-sources.adoc"
  fi
}

topic_skills() {
  # agentskills/agentskills repository - all .mdx files
  local agentskills
  agentskills=$(fetch "github://agentskills/agentskills")
  find "$agentskills" -name "*.mdx" -type f | sort | while read -r file; do
    local rel="${file#"$agentskills"/}"
    local slug="${rel#docs/}"
    slug="${slug%.mdx}"
    local published="https://agentskills.io/$slug"
    run "curl -s 'https://raw.githubusercontent.com/agentskills/agentskills/main/$rel'  # published to $published" cat "$file"
  done

  # Claude Code documentation
  run "curl -sfS 'https://code.claude.com/docs/en/skills.md'  # published to https://code.claude.com/docs/en/skills" \
    curl -sfS 'https://code.claude.com/docs/en/skills.md'

  # Claude platform overview
  run "curl -sfS 'https://platform.claude.com/docs/en/agents-and-tools/agent-skills/overview.md'  # published to https://platform.claude.com/docs/en/agents-and-tools/agent-skills/overview" \
    curl -sfS 'https://platform.claude.com/docs/en/agents-and-tools/agent-skills/overview.md'

  # Claude platform best practices
  run "curl -sfS 'https://platform.claude.com/docs/en/agents-and-tools/agent-skills/best-practices.md'  # published to https://platform.claude.com/docs/en/agents-and-tools/agent-skills/best-practices" \
    curl -sfS 'https://platform.claude.com/docs/en/agents-and-tools/agent-skills/best-practices.md'

  # Anthropic skills repository
  run "curl -sfS 'https://raw.githubusercontent.com/anthropics/skills/refs/heads/main/skills/skill-creator/SKILL.md'" \
    curl -sfS 'https://raw.githubusercontent.com/anthropics/skills/refs/heads/main/skills/skill-creator/SKILL.md'

  # Gemini CLI skills
  run "curl -sfS 'https://raw.githubusercontent.com/google-gemini/gemini-cli/main/docs/cli/skills.md'  # published to https://geminicli.com/docs/cli/skills/" \
    curl -sfS 'https://raw.githubusercontent.com/google-gemini/gemini-cli/main/docs/cli/skills.md'

  # OpenAI Codex skills
  run "curl -sfS 'https://developers.openai.com/codex/skills.md'  # published to https://developers.openai.com/codex/skills/" \
    curl -sfS 'https://developers.openai.com/codex/skills.md'
  run "curl -sfS 'https://developers.openai.com/api/docs/guides/tools-skills.md'  # published to https://developers.openai.com/api/docs/guides/tools-skills/" \
    curl -sfS 'https://developers.openai.com/api/docs/guides/tools-skills.md'
}

topic_gemini_sdk_js() {
  run "curl -sfS 'https://raw.githubusercontent.com/googleapis/js-genai/main/codegen_instructions.md'" \
    curl -sfS 'https://raw.githubusercontent.com/googleapis/js-genai/main/codegen_instructions.md'
}

topic_compose_architecture() {
  local url
  for url in \
    "https://developer.android.com/develop/ui/compose/why-adopt" \
    "https://developer.android.com/develop/ui/compose/mental-model" \
    "https://developer.android.com/develop/ui/compose/lifecycle" \
    "https://developer.android.com/develop/ui/compose/side-effects" \
    "https://developer.android.com/develop/ui/compose/phases" \
    "https://developer.android.com/develop/ui/compose/state" \
    "https://developer.android.com/develop/ui/compose/state-hoisting" \
    "https://developer.android.com/develop/ui/compose/state-saving" \
    "https://developer.android.com/develop/ui/compose/state-lifespans" \
    "https://developer.android.com/develop/ui/compose/state-callbacks" \
    "https://developer.android.com/develop/ui/compose/architecture" \
    "https://developer.android.com/develop/ui/compose/layering" \
    "https://developer.android.com/develop/ui/compose/compositionlocal"; do
    run "curl -sfS '$url'" curl -sfS "$url.md.txt"
  done
}

# =============================================================================
# TOPIC REGISTRY
# =============================================================================

TOPICS=(
  "gemini-api:Gemini API documentation and examples"
  "mcp-server:MCP server documentation and specification"
  "gemini-cli:Gemini CLI documentation (all)"
  "inkyframe:Pimoroni Inky Frame documentation"
  "rpi:Raspberry Pi documentation"
  "skills:Agent skills documentation (Claude, Gemini CLI, OpenAI Codex)"
  "gemini-sdk-js:Google Gemini JavaScript SDK codegen instructions"
  "compose-architecture:Android Compose Architecture documentation"
)

# =============================================================================
# USAGE AND ARGUMENT PARSING
# =============================================================================

usage() {
  cat <<EOF
Usage: $SCRIPT_NAME <topic>

Generate aggregated context for a specific topic. Output is written to stdout
as a shell_session XML format suitable for AI agent consumption.

Topics:
EOF
  for entry in "${TOPICS[@]}"; do
    local name="${entry%%:*}"
    local desc="${entry#*:}"
    printf "  %-22s %s\n" "$name" "$desc"
  done
  cat <<EOF

Options:
  -h, --help    Display this help message and exit
  --list        List available topics (names only)

Examples:
  $SCRIPT_NAME gemini-api
    Generate Gemini API context to stdout

  $SCRIPT_NAME gemini-api > gemini-api-context.xml
    Save context to a file

  $SCRIPT_NAME gemini-api | pbcopy
    Copy context to clipboard (macOS)
EOF
  exit 0
}

list_topics() {
  for entry in "${TOPICS[@]}"; do
    echo "${entry%%:*}"
  done
  exit 0
}

emit_header() {
  local topic_desc="$1"
  local timestamp
  timestamp=$(date +%Y-%m-%dT%H:%M:%S%z)
  echo "<shell_session>"
  cat <<EOF
<context_summary>
  <generated_at>$timestamp</generated_at>
  <purpose>
    Topic: $topic_desc

    This content represents a recorded shell session designed to provide context for an AI agent.
    It aggregates resources (local files, remote URLs, system info) by capturing shell commands
    and their output.
  </purpose>
  <structure>
    The session is organized as a sequence of &lt;entry&gt; elements:
    1. &lt;command&gt;: The command string acting as the data source. (e.g., "cat file.txt" or "curl url")
       Treat this as the source of truth for where the data originated.
    2. &lt;output&gt;: The raw content returned by that command.
  </structure>
  <guidelines>
    - PROVENANCE: The &lt;command&gt; element indicates an approximate source for the data. In some cases
      the actual retrieval method may differ (e.g., fetched from a local cache or extracted archive).
    - SNAPSHOT: Outputs represent a best-effort snapshot at the time this script was run.
  </guidelines>
</context_summary>
EOF
}

emit_footer() {
  echo "</shell_session>"
}

# =============================================================================
# MAIN
# =============================================================================

if [[ $# -lt 1 ]]; then
  usage
fi

case "$1" in
  -h | --help)
    usage
    ;;
  --list)
    list_topics
    ;;
  -*)
    echo "$SCRIPT_NAME: unknown option: $1" >&2
    exit 1
    ;;
  *)
    TOPIC="$1"
    ;;
esac

# Validate topic
TOPIC_FUNC="topic_${TOPIC//-/_}"
if ! declare -f "$TOPIC_FUNC" >/dev/null 2>&1; then
  echo "$SCRIPT_NAME: unknown topic: $TOPIC" >&2
  echo "Run '$SCRIPT_NAME --list' to see available topics" >&2
  exit 1
fi

# Check dependencies
require curl
require jq
require python3

# Create build directory
BUILD_DIR=$(mktemp -d "${TMPDIR:-/tmp}/$SCRIPT_NAME.XXXXXXXXXX")
trap 'rm -rf "$BUILD_DIR"' EXIT

# Look up topic description
TOPIC_DESC=""
for entry in "${TOPICS[@]}"; do
  if [[ "${entry%%:*}" == "$TOPIC" ]]; then
    TOPIC_DESC="${entry#*:}"
    break
  fi
done

# Output generation
OUTPUT_FILE="$BUILD_DIR/output.xml"

{
  emit_header "$TOPIC_DESC"
  "$TOPIC_FUNC"
  emit_footer
} >"$OUTPUT_FILE"

# Check output size (1MB limit)
SIZE=$(wc -c <"$OUTPUT_FILE" | tr -d ' \t')
if ((SIZE > 1000000)); then
  echo "$SCRIPT_NAME: warning: output size ($SIZE bytes) exceeds 1MB" >&2
fi

cat "$OUTPUT_FILE"
