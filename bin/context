#!/usr/bin/env bash

# context - Generate combined repomix context for various topics
#
# Each topic is a bash function that uses fetch() to download sources
# and standard cp to assemble files into $MIX_DIR for repomix.

set -e

SCRIPT_NAME=$(basename "$0")

# =============================================================================
# HELPER FUNCTIONS
# =============================================================================

require() {
  hash "$@" || {
    echo "$SCRIPT_NAME: command '$1' not found" >&2
    exit 127
  }
}

# fetch - Download a source and return its local path
#
# Usage:
#   fetch github://owner/repo              Download default branch, return dir path
#   fetch github://owner/repo@branch       Download specific branch, return dir path
#   fetch https://example.com/file.txt     Download URL, return file path
#
# All downloads are cached in $BUILD_DIR for the duration of the script.
fetch() {
  local url="$1"

  if [[ "$url" =~ ^github://(.+) ]]; then
    local repo_spec="${BASH_REMATCH[1]}"
    local repo branch="main"

    # Parse owner/repo@branch
    if [[ "$repo_spec" =~ ^(.+)@(.+)$ ]]; then
      repo="${BASH_REMATCH[1]}"
      branch="${BASH_REMATCH[2]}"
    else
      repo="$repo_spec"
    fi

    local repo_slug="${repo//\//-}"
    local extract_dir="$BUILD_DIR/repos/$repo_slug"

    if [[ ! -d "$extract_dir" ]]; then
      local archive_url="https://github.com/${repo}/archive/refs/heads/${branch}.zip"
      local zip_file="$BUILD_DIR/${repo_slug}.zip"
      local archive_name="${repo##*/}-${branch}"

      curl -fsSL -o "$zip_file" "$archive_url"
      mkdir -p "$extract_dir"
      unzip -o -q "$zip_file" -d "$BUILD_DIR/temp_extract"
      mv "$BUILD_DIR/temp_extract/$archive_name"/* "$extract_dir/"
      rm -rf "$BUILD_DIR/temp_extract" "$zip_file"
    fi

    echo "$extract_dir"

  elif [[ "$url" =~ ^https?:// ]]; then
    local filename
    filename=$(basename "$url")
    local dest="$BUILD_DIR/urls/$filename"

    if [[ ! -f "$dest" ]]; then
      mkdir -p "$BUILD_DIR/urls"
      curl -fsSL -o "$dest" "$url"
    fi

    echo "$dest"

  else
    echo "$SCRIPT_NAME: fetch: unsupported URL scheme: $url" >&2
    return 1
  fi
}

# add_source_comment - Prepend source attribution to a file
#
# Usage: add_source_comment FILE SOURCE_URL
#
# Detects file type and uses appropriate comment syntax.
add_source_comment() {
  local file="$1"
  local source="$2"
  local ext="${file##*.}"
  local tmpfile

  tmpfile=$(mktemp)

  case "$ext" in
    md|mdx|html)
      echo "<!-- Source: $source -->" > "$tmpfile"
      echo "" >> "$tmpfile"
      ;;
    adoc)
      echo "// Source: $source" > "$tmpfile"
      echo "" >> "$tmpfile"
      ;;
    py|sh|bash|fish|yaml|yml|toml)
      echo "# Source: $source" > "$tmpfile"
      echo "" >> "$tmpfile"
      ;;
    js|ts|tsx|jsx|json|jsonc)
      echo "// Source: $source" > "$tmpfile"
      echo "" >> "$tmpfile"
      ;;
    rst)
      echo ".. Source: $source" > "$tmpfile"
      echo "" >> "$tmpfile"
      ;;
    *)
      # Unknown type - no comment added
      cat "$file" > "$tmpfile"
      mv "$tmpfile" "$file"
      return
      ;;
  esac

  cat "$file" >> "$tmpfile"
  mv "$tmpfile" "$file"
}

# copy_with_source - Copy file(s) to MIX_DIR with source attribution
#
# Usage: copy_with_source SOURCE_URL FILE... DEST
#
# Like cp, but adds source attribution header to each file.
copy_with_source() {
  local source_url="$1"
  shift

  # Last arg is destination
  local dest="${*: -1}"
  local files=("${@:1:$#-1}")

  for file in "${files[@]}"; do
    if [[ -d "$file" ]]; then
      # For directories, copy recursively and add source to each file
      local base
      base=$(basename "$file")
      cp -r "$file" "$dest/"
      find "$dest/$base" -type f | while read -r f; do
        add_source_comment "$f" "$source_url"
      done
    elif [[ -f "$file" ]]; then
      cp "$file" "$dest/"
      local basename
      basename=$(basename "$file")
      add_source_comment "$dest/$basename" "$source_url"
    fi
  done
}

# copy_repo_tree - Copy files from a repo with per-file source URLs
#
# Usage: copy_repo_tree REPO_BASE_URL REPO_PATH SRC_DIR DEST_DIR [GLOB_PATTERN]
#
# Copies files from SRC_DIR to DEST_DIR, adding source attribution headers
# that include the full path within the repo for each file.
#
# Example:
#   copy_repo_tree "github://owner/repo" "$repo" "$repo/docs" "$MIX_DIR/docs" "*.md"
#
# This will copy all .md files from $repo/docs to $MIX_DIR/docs, adding source
# headers like "github://owner/repo/docs/file.md" to each file.
copy_repo_tree() {
  local repo_base_url="$1"
  local repo_path="$2"
  local src_dir="$3"
  local dest_dir="$4"
  local glob_pattern="${5:-*}"

  mkdir -p "$dest_dir"

  # Find files matching the pattern and copy with source attribution
  find "$src_dir" -name "$glob_pattern" -type f | while read -r file; do
    # Calculate relative path from repo root
    local rel_from_repo="${file#$repo_path/}"
    local source_url="$repo_base_url/$rel_from_repo"

    # Calculate relative path from src_dir to preserve directory structure
    local rel_from_src="${file#$src_dir/}"
    local dest_file="$dest_dir/$rel_from_src"

    # Create destination directory structure
    mkdir -p "$(dirname "$dest_file")"

    # Copy and add source comment
    cp "$file" "$dest_file"
    add_source_comment "$dest_file" "$source_url"
  done
}

# filter_ipynb - Filter binary image data from Jupyter notebooks
#
# Usage: filter_ipynb INPUT OUTPUT
filter_ipynb() {
  local input="$1"
  local output="$2"
  jq 'walk(if type == "object" and has("data") and (.data | type == "object") then
    .data |= with_entries(select(.key | test("^image/") | not))
    else . end) |
    walk(if type == "object" and has("outputs") then
    .outputs |= map(if .data then .data |= with_entries(select(.key | test("^image/") | not)) else . end)
    else . end)' "$input" > "$output"
}

# =============================================================================
# TOPIC DEFINITIONS
# =============================================================================
# Each topic is a bash function that:
#   1. Uses fetch() to download sources
#   2. Uses cp (or copy_with_source) to assemble files into $MIX_DIR
#   3. Can use any standard shell commands for filtering/transformation

topic_gemini_api() {
  local repo
  repo=$(fetch "github://google-gemini/cookbook")

  # Copy and filter notebooks (remove binary image data)
  mkdir -p "$MIX_DIR/notebooks"
  filter_ipynb "$repo/examples/Book_illustration.ipynb" "$MIX_DIR/notebooks/Book_illustration.ipynb"
  add_source_comment "$MIX_DIR/notebooks/Book_illustration.ipynb" "github://google-gemini/cookbook/examples/Book_illustration.ipynb"
  filter_ipynb "$repo/quickstarts/Image_out.ipynb" "$MIX_DIR/notebooks/Image_out.ipynb"
  add_source_comment "$MIX_DIR/notebooks/Image_out.ipynb" "github://google-gemini/cookbook/quickstarts/Image_out.ipynb"

  # Fetch documentation URLs
  local urls=(
    "https://ai.google.dev/gemini-api/docs/image-generation.md.txt"
    "https://ai.google.dev/gemini-api/docs/image-understanding.md.txt"
    "https://ai.google.dev/gemini-api/docs/models.md.txt"
    "https://ai.google.dev/gemini-api/docs/prompting-strategies.md.txt"
    "https://ai.google.dev/gemini-api/docs/structured-output.md.txt"
    "https://ai.google.dev/gemini-api/docs/text-generation.md.txt"
  )
  for url in "${urls[@]}"; do
    local file dest_name
    file=$(fetch "$url")
    dest_name=$(basename "$url" .txt)  # Remove .txt suffix
    cp "$file" "$MIX_DIR/$dest_name"
    add_source_comment "$MIX_DIR/$dest_name" "$url"
  done
}

topic_gemini_sdk() {
  local repo
  repo=$(fetch "github://googleapis/js-genai")

  copy_with_source "github://googleapis/js-genai/src" "$repo/src" "$MIX_DIR/"
}

topic_mcp_server() {
  local repo
  repo=$(fetch "github://modelcontextprotocol/modelcontextprotocol")

  mkdir -p "$MIX_DIR/docs" "$MIX_DIR/specification"
  copy_with_source "github://modelcontextprotocol/modelcontextprotocol/docs/docs/learn" \
    "$repo/docs/docs/learn/server-concepts.mdx" \
    "$repo/docs/docs/learn/architecture.mdx" \
    "$MIX_DIR/docs/"
  copy_with_source "github://modelcontextprotocol/modelcontextprotocol/docs/specification/2025-11-25" \
    "$repo/docs/specification/2025-11-25" "$MIX_DIR/"
}

topic_mcp_typescript_sdk() {
  local repo
  repo=$(fetch "github://modelcontextprotocol/typescript-sdk")

  copy_with_source "github://modelcontextprotocol/typescript-sdk" "$repo/README.md" "$MIX_DIR/"
}

topic_gemini_cli() {
  local repo
  repo=$(fetch "github://google-gemini/gemini-cli")

  copy_with_source "github://google-gemini/gemini-cli/docs" "$repo/docs" "$MIX_DIR/"
}

topic_gemini_cli_extensions() {
  local repo
  repo=$(fetch "github://google-gemini/gemini-cli")

  mkdir -p "$MIX_DIR/extensions"
  copy_with_source "github://google-gemini/gemini-cli/docs/extensions" "$repo/docs/extensions"/*.md "$MIX_DIR/extensions/"
}

topic_gemini_cli_hooks() {
  local repo
  repo=$(fetch "github://google-gemini/gemini-cli")

  mkdir -p "$MIX_DIR/hooks"
  copy_with_source "github://google-gemini/gemini-cli/docs/hooks" "$repo/docs/hooks"/*.md "$MIX_DIR/hooks/"
}

topic_inkyframe() {
  local inky pico
  inky=$(fetch "github://pimoroni/inky-frame")
  pico=$(fetch "github://pimoroni/pimoroni-pico")

  mkdir -p "$MIX_DIR/inky-frame" "$MIX_DIR/pico"
  copy_with_source "github://pimoroni/inky-frame/docs" "$inky/docs" "$MIX_DIR/inky-frame/"
  copy_with_source "github://pimoroni/inky-frame/examples" "$inky/examples" "$MIX_DIR/inky-frame/"
  copy_with_source "github://pimoroni/inky-frame/modules" "$inky/modules" "$MIX_DIR/inky-frame/"
  copy_with_source "github://pimoroni/pimoroni-pico/micropython/modules/picographics" \
    "$pico/micropython/modules/picographics" "$MIX_DIR/pico/"

  # Fetch URLs
  local mpremote pimoroni_learn
  mpremote=$(fetch "https://docs.micropython.org/en/latest/_sources/reference/mpremote.rst.txt")
  mkdir -p "$MIX_DIR/mpremote"
  cp "$mpremote" "$MIX_DIR/mpremote/mpremote.rst"
  add_source_comment "$MIX_DIR/mpremote/mpremote.rst" "https://docs.micropython.org/en/latest/_sources/reference/mpremote.rst.txt"

  pimoroni_learn=$(fetch "https://r.jina.ai/https://learn.pimoroni.com/article/getting-started-with-inky-frame")
  mkdir -p "$MIX_DIR/pimoroni-learn"
  cp "$pimoroni_learn" "$MIX_DIR/pimoroni-learn/getting-started-with-inky-frame.md"
  add_source_comment "$MIX_DIR/pimoroni-learn/getting-started-with-inky-frame.md" \
    "https://learn.pimoroni.com/article/getting-started-with-inky-frame"
}

topic_rpi() {
  local repo
  repo=$(fetch "github://raspberrypi/documentation@master")

  local src="$repo/documentation/asciidoc/computers"

  # Positive patterns only - explicitly list included directories
  # (One-time snapshot; new upstream directories won't auto-include)
  for dir in config_txt configuration getting-started os raspberry-pi remote-access; do
    # Copy index file if it exists
    if [[ -f "$src/$dir.adoc" ]]; then
      copy_with_source "github://raspberrypi/documentation/documentation/asciidoc/computers/$dir.adoc" \
        "$src/$dir.adoc" "$MIX_DIR/"
    fi
    # Copy directory contents
    if [[ -d "$src/$dir" ]]; then
      copy_with_source "github://raspberrypi/documentation/documentation/asciidoc/computers/$dir" \
        "$src/$dir" "$MIX_DIR/"
    fi
  done

  # Additional standalone files
  if [[ -f "$src/software-sources.adoc" ]]; then
    copy_with_source "github://raspberrypi/documentation/documentation/asciidoc/computers/software-sources.adoc" \
      "$src/software-sources.adoc" "$MIX_DIR/"
  fi
}

topic_skills() {
  # Agent skills documentation from multiple sources

  # 1. agentskills/agentskills repository - all .mdx files
  local agentskills_repo
  agentskills_repo=$(fetch "github://agentskills/agentskills")
  copy_repo_tree "github://agentskills/agentskills" "$agentskills_repo" "$agentskills_repo" "$MIX_DIR/agentskills" "*.mdx"

  # 2. Claude platform best practices
  local best_practices
  best_practices=$(fetch "https://platform.claude.com/docs/en/agents-and-tools/agent-skills/best-practices.md")
  cp "$best_practices" "$MIX_DIR/best-practices.md"
  add_source_comment "$MIX_DIR/best-practices.md" "https://platform.claude.com/docs/en/agents-and-tools/agent-skills/best-practices.md"

  # 3. Anthropic skills repository - skill-creator SKILL.md
  local anthropic_skills
  anthropic_skills=$(fetch "https://raw.githubusercontent.com/anthropics/skills/refs/heads/main/skills/skill-creator/SKILL.md")
  cp "$anthropic_skills" "$MIX_DIR/skill-creator-SKILL.md"
  add_source_comment "$MIX_DIR/skill-creator-SKILL.md" "https://github.com/anthropics/skills/blob/main/skills/skill-creator/SKILL.md"

  # 4. Gemini CLI skills documentation
  local gemini_cli_skills
  gemini_cli_skills=$(fetch "https://raw.githubusercontent.com/google-gemini/gemini-cli/main/docs/cli/skills.md")
  cp "$gemini_cli_skills" "$MIX_DIR/gemini-cli-skills.md"
  add_source_comment "$MIX_DIR/gemini-cli-skills.md" "https://github.com/google-gemini/gemini-cli/blob/main/docs/cli/skills.md"

  # 5. OpenAI Codex skills documentation
  local openai_skills
  openai_skills=$(fetch "https://developers.openai.com/codex/skills.md")
  cp "$openai_skills" "$MIX_DIR/openai-codex-skills.md"
  add_source_comment "$MIX_DIR/openai-codex-skills.md" "https://developers.openai.com/codex/skills.md"

  # 6. OpenAI Codex create-skill documentation
  local openai_create_skill
  openai_create_skill=$(fetch "https://developers.openai.com/codex/skills/create-skill.md")
  cp "$openai_create_skill" "$MIX_DIR/openai-codex-create-skill.md"
  add_source_comment "$MIX_DIR/openai-codex-create-skill.md" "https://developers.openai.com/codex/skills/create-skill.md"
}

# =============================================================================
# TOPIC REGISTRY
# =============================================================================

TOPICS=(
  "gemini-api:Gemini API documentation and examples"
  "gemini-sdk:Gemini TypeScript/JavaScript SDK"
  "mcp-server:MCP server documentation and specification"
  "mcp-typescript-sdk:MCP TypeScript SDK documentation"
  "gemini-cli:Gemini CLI documentation (all)"
  "gemini-cli-extensions:Gemini CLI extensions documentation"
  "gemini-cli-hooks:Gemini CLI hooks documentation"
  "inkyframe:Pimoroni Inky Frame documentation"
  "rpi:Raspberry Pi documentation"
  "skills:Agent skills documentation (Claude, Gemini CLI, OpenAI Codex)"
)

# =============================================================================
# USAGE AND ARGUMENT PARSING
# =============================================================================

usage() {
  cat <<EOF
Usage: $SCRIPT_NAME <topic>

Generate combined repomix context for a specific topic. Output is written to
stdout and can be redirected to a file or piped to other commands.

Topics:
EOF
  for entry in "${TOPICS[@]}"; do
    local name="${entry%%:*}"
    local desc="${entry#*:}"
    printf "  %-22s %s\n" "$name" "$desc"
  done
  cat <<EOF

Options:
  -h, --help    Display this help message and exit
  --list        List available topics (names only)

Examples:
  $SCRIPT_NAME gemini-api
    Generate Gemini API context to stdout

  $SCRIPT_NAME gemini-api > gemini-api-context.txt
    Save context to a file

  $SCRIPT_NAME gemini-api | pbcopy
    Copy context to clipboard (macOS)
EOF
  exit 0
}

list_topics() {
  for entry in "${TOPICS[@]}"; do
    echo "${entry%%:*}"
  done
  exit 0
}

# =============================================================================
# MAIN
# =============================================================================

if [[ $# -lt 1 ]]; then
  usage
fi

case "$1" in
  -h|--help)
    usage
    ;;
  --list)
    list_topics
    ;;
  -*)
    echo "$SCRIPT_NAME: unknown option: $1" >&2
    exit 1
    ;;
  *)
    TOPIC="$1"
    ;;
esac

# Validate topic
TOPIC_FUNC="topic_${TOPIC//-/_}"
if ! declare -f "$TOPIC_FUNC" > /dev/null 2>&1; then
  echo "$SCRIPT_NAME: unknown topic: $TOPIC" >&2
  echo "Run '$SCRIPT_NAME --list' to see available topics" >&2
  exit 1
fi

# Check dependencies
require curl
require unzip
require repomix
require jq

# Create build directory
BUILD_DIR=$(mktemp -d "${TMPDIR:-/tmp}/$SCRIPT_NAME.XXXXXXXXXX")
MIX_DIR="$BUILD_DIR/mix"
mkdir -p "$MIX_DIR"
trap 'rm -rf "$BUILD_DIR"' EXIT

# Run the topic function to assemble files
"$TOPIC_FUNC"

# Run repomix on the assembled directory
repomix "$MIX_DIR" --no-security-check --quiet -o -
